# Assignment 4

## Hybrid and Distributed Parallel Computing

### Задание 1. Суммирование массива на CPU и GPU (CUDA, глобальная память)

**Файл:** `task1.cu`
**Описание:**
Вычисляется сумма элементов массива размером 100 000:

* Последовательно на CPU
* Параллельно на GPU с использованием `atomicAdd` в глобальной памяти

**Компиляция (Google Colab, GPU T4):**

```bash
nvcc task1.cu -o task1 -arch=sm_75 -std=c++11
```

**Запуск:**

```bash
./task1
```

---

### Задание 2. Префиксная сумма (scan) с использованием shared memory (CUDA)

**Файл:** `task2.cu`
**Описание:**
Реализован параллельный префиксный сумматор (inclusive scan) для массива из 1 000 000 элементов:

* Последовательно на CPU
* Параллельно на GPU с использованием разделяемой памяти и двухфазного алгоритма (block scan + добавление сумм блоков)

**Компиляция:**

```bash
nvcc task2.cu -o task2 -arch=sm_75 -std=c++11
```

**Запуск:**

```bash
./task2
```

---

### Задание 3. Гибридная обработка CPU + GPU (CUDA)

**Файл:** `task3.cu`
**Описание:**
Массив обрабатывается тремя способами:

1. Полностью на CPU
2. Полностью на GPU
3. Гибридно: первая половина на CPU, вторая на GPU

Выполняется операция умножения элементов на 2 и сравнение времени.

**Компиляция:**

```bash
nvcc task3.cu -o task3 -arch=sm_75 -std=c++11
```

**Запуск:**

```bash
./task3
```

---

### Задание 4. Распределённые вычисления с использованием MPI

**Файл:** `mpi_task4.cpp`
**Описание:**
Реализована распределённая программа на MPI:

* Массив из 1 000 000 элементов делится между процессами
* Каждый процесс вычисляет локальную сумму
* Общая сумма собирается с помощью `MPI_Reduce`
* Измеряется время для 2, 4 и 8 процессов

#### Установка MPI в Google Colab

```bash
apt-get update
apt-get install -y openmpi-bin openmpi-common libopenmpi-dev
```

#### Компиляция:

```bash
mpicxx mpi_task4.cpp -o mpi_app
```

#### Запуск:

```bash
mpirun --allow-run-as-root --oversubscribe -np 2 ./mpi_app
mpirun --allow-run-as-root --oversubscribe -np 4 ./mpi_app
mpirun --allow-run-as-root --oversubscribe -np 8 ./mpi_app
```

---

## Выводы

* CUDA обеспечивает значительное ускорение по сравнению с CPU для задач суммирования и сканирования.
* Использование shared memory (Task 2) даёт более высокую производительность по сравнению с глобальной памятью.
* Гибридная модель (CPU + GPU) показывает промежуточную производительность между чисто CPU и чисто GPU реализациями.
* MPI позволяет эффективно масштабировать вычисления при увеличении числа процессов (2, 4, 8), уменьшая общее время выполнения за счёт параллельной обработки и редукции.

## Автор проекта  
Студент: Aruzhan Bissimbayeva 

Группа: ADA-2403M

## Преподаватель  
Проверяющий: Sadvakassova Kuralay
