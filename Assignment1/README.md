# Assignment_1_HP_Aruzhan_Bissimbayeva
Assignment 1 of Heterogeneous Parallelization. Group ADA-2403M. Student: Aruzhan Bissimbayeva
# Лабораторная работа: Динамическая память, алгоритмы поиска и OpenMP  

## Описание проекта  
Репозиторий содержит решения четырех заданий на C++.  
Каждая программа выполняет поставленные задачи, сопровождается подробными комментариями и измерениями времени выполнения (там, где требуется).  

## Содержание
Задания расположены в отдельных файлах:
1. **Задание 1**
   "Реализуйте программу на C++, которая динамически выделяет массив из 50 000 целых
чисел, заполняет его случайными значениями от 1 до 100, вычисляет среднее значение
элементов массива и корректно освобождает выделенную память."

    В коде task1 было выполнено:
   - Динамическое выделение массива из 50 000 элементов  
   - Заполнение случайными числами  
   - Вычисление среднего значения  
   - Корректное освобождение памяти  

3. **Задание 2**
    "Создайте массив из 1 000 000 целых чисел и реализуйте последовательный алгоритм
поиска минимального и максимального элементов. Замерьте время выполнения алгоритма."

    В коде task2 было выполнено:
   - Создание массива из 1 000 000 целых чисел  
   - Последовательный поиск минимального и максимального значений  
   - Измерение времени выполнения  

5. **Задание 3**
    "Используя OpenMP, реализуйте параллельный поиск минимального и максимального
элементов массива из задания 2. Сравните время выполнения последовательной и
параллельной реализаций."

     В коде task3 было выполнено:
   - Параллельный поиск минимального и максимального значений с использованием OpenMP  
   - Сравнение результатов с последовательной реализацией  
   - Замер времени выполнения  

7. **Задание 4**
    "Создайте массив из 5 000 000 чисел и реализуйте вычисление среднего значения
элементов массива последовательным способом и с использованием OpenMP с редукцией.
Сравните время выполнения обеих реализаций."

    В коде task4 было выполнено:
   - Создание массива из 5 000 000 элементов  
   - Последовательное и параллельное вычисление среднего значения  
   - Использование OpenMP reduction  
   - Сравнение времени выполнения и вычисление ускорения  

## Компиляция и запуск
Для компиляции программ рекомендуется компилятор g++ с поддержкой OpenMP.
Примеры подходящих компиляторов:
- GCC / G++  
- Clang  
- MSVC (поддерживает OpenMP начиная с VS 2019)

## Компиляция и запуск
### Linux / MacOS (g++)

g++ task1.cpp -o task1.exe

g++ task2.cpp -o task2.exe

g++ -fopenmp task3.cpp -o task3.exe

g++ -fopenmp task4.cpp -o task4.exe

./task1.exe

./task2.exe

./task3.exe

./task4.exe

### Windows (MinGW + OpenMP)
g++ -fopenmp task3.cpp -o task3.exe

task3.exe

## Используемые библиотеки и технологии
- `<iostream>`, `<cstdlib>`, `<ctime>` - работа со стандартными библиотеками  
- `<chrono>` – замер времени выполнения  
- OpenMP (pragma omp parallel, reduction, critical)  

## Результаты
Запуск программ позволяет:
- сравнить производительность последовательных и параллельных алгоритмов;  
- оценить влияние параллелизма и числа потоков;  
- наблюдать ускорение при работе с большими массивами данных.


## Контрольные вопросы и ответы
**1. В чём отличие динамического массива от статического массива в языке C++?**

**Ответ:** Статический массив имеет фиксированный размер, определяемый на этапе компиляции, и хранится в стеке. Динамический массив выделяется в куче во время выполнения программы, его размер можно задавать произвольно при выполнении, но память требуется освобождать вручную.

**2. Что такое указатель и зачем он используется при работе с динамической памятью?**

**Ответ:** указатель - это переменная, которая хранит адрес области памяти.
При работе с динамическими массивами указатель используется для получения доступа к выделенной области памяти и управлению ею.

**3. Почему важно корректно освобождать память после использования динамических массивов?**  

**Ответ:** если память не освобождать вручную с помощью операторов delete или delete[], возникают утечки памяти.
Это приводит к постоянному росту потребления памяти программой и снижению эффективности использования ресурсов.

**4. В чём разница между последовательной и параллельной обработкой массива?**

**Ответ:** последовательная обработка выполняет операции над элементами один за другим в одном потоке. Параллельная обработка разделяет работу между несколькими потоками, что позволяет одновременно обрабатывать разные фрагменты массива и потенциально сокращать время выполнения.

**5. Что делает директива #pragma omp parallel for?** 

**Ответ:** Эта директива организует параллельное выполнение цикла for, автоматически распределяя итерации цикла между несколькими потоками и синхронизируя выполнение при необходимости.

**6. Для чего используется механизм reduction в OpenMP?**

**Ответ:** reduction обеспечивает безопасное объединение частичных результатов вычислений, выполняемых потоками, в одну итоговую переменную с применением указанной операции (например, суммы) или находит максимум и минимум.

**7. Почему при параллельном вычислении суммы необходимо использовать reduction, а не обычную переменную?**  

**Ответ:** при использовании общей переменной возникает состояние гонки - несколько потоков одновременно записывают в одну область памяти. Reduction устраняет этот конфликт, создавая копии переменной для каждого потока и безопасно объединяя результаты.

**8. Какие факторы могут привести к тому, что параллельная версия программы будет работать медленнее последовательной?**  

**Ответ:** параллельная реализация может проигрывать по времени из-за накладных расходов на создание потоков и их синхронизацию, из-за малого объема вычислений, конфликтов доступа к памяти, неэффективного разделения работы, а также из-за аппаратных ограничений.


## Автор проекта  
Студент: Aruzhan Bissimbayeva 

Группа: ADA-2403M

## Преподаватель  
Проверяющий: Sadvakassova Kuralay







